{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5b56da8208ae380fa2c15171ec3bd1c59fd37e61d99a7ebd9f8c7e6e7af5d3db"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021.07.05. MON\n",
    "#Hankyeong\n",
    "\n",
    "#00. 패키지 호출\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import warnings \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#00-1. 시각화 옵션 설정\n",
    "%matplotlib inline\n",
    "\n",
    "#00-2. warning message ignore\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#00-3. 씨드넘버 설정\n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#05. 텍스트 데이터 전처리하기. \n",
    "#(1) 텍스트 데이터 생성하기. \n",
    "text = '''\n",
    "    경마장에 있는 말이 뛰고 있다. \\n \n",
    "    그의 말이 법이다. \\n\n",
    "    가는 말이 고와야 오는 말이 곱다. \\n\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'말이': 1,\n",
       " '경마장에': 2,\n",
       " '있는': 3,\n",
       " '뛰고': 4,\n",
       " '있다': 5,\n",
       " '그의': 6,\n",
       " '법이다': 7,\n",
       " '가는': 8,\n",
       " '고와야': 9,\n",
       " '오는': 10,\n",
       " '곱다': 11}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#(2) Tonkenizer 객체 지정하기. \n",
    "t = Tokenizer()\n",
    "\n",
    "#(3) text를 Token으로 분리하기(토큰화하기). \n",
    "t.fit_on_texts([text])\n",
    "\n",
    "#(4) Token의 인덱스값 파악하기. \n",
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('경마장에', 1),\n",
       "             ('있는', 1),\n",
       "             ('말이', 4),\n",
       "             ('뛰고', 1),\n",
       "             ('있다', 1),\n",
       "             ('그의', 1),\n",
       "             ('법이다', 1),\n",
       "             ('가는', 1),\n",
       "             ('고와야', 1),\n",
       "             ('오는', 1),\n",
       "             ('곱다', 1)])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#PLUS. Token들의 빈도 확인하기.\n",
    "t.word_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#(5) 단어 집합 설정하기. \n",
    "voca_size = len(t.word_index) +1 \n",
    "voca_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHY? keras의 Tokenizer 객체는 토큰화 시 인덱스 번호가 1부터 시작함.\n",
    "#     허나 원핫인코딩 처리시 배열의 인덱스가 0부터 시작하기 때문에, \n",
    "#     크기를 동일하게 하기 위해 실제 단어 집합의 크기보다 +1로 설정해야함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[6, 1, 7]]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#PLUS. sequence를 index 번호로 변환(벡터화)하기. \n",
    "t.texts_to_sequences(['그의 말이 법이다.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[2, 3],\n",
       " [2, 3, 1],\n",
       " [2, 3, 1, 4],\n",
       " [2, 3, 1, 4, 5],\n",
       " [6, 1],\n",
       " [6, 1, 7],\n",
       " [8, 1],\n",
       " [8, 1, 9],\n",
       " [8, 1, 9, 10],\n",
       " [8, 1, 9, 10, 1],\n",
       " [8, 1, 9, 10, 1, 11]]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "#(6) 문장들을 index 번호로 변환하기. \n",
    "sequences = [] \n",
    "for line in text.split('\\n') : \n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(encoded)) :\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#(7) 패딩 처리 전 sequence의 최대 원소 수 파악하기.\n",
    "max_len = max([len(sequence) for sequence in sequences])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  0,  2,  3,  1],\n",
       "       [ 0,  0,  2,  3,  1,  4],\n",
       "       [ 0,  2,  3,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  6,  1,  7],\n",
       "       [ 0,  0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9],\n",
       "       [ 0,  0,  8,  1,  9, 10],\n",
       "       [ 0,  8,  1,  9, 10,  1],\n",
       "       [ 8,  1,  9, 10,  1, 11]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#(8) 패딩 처리하기. \n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "sequences"
   ]
  },
  {
   "source": [
    "#MEMO. pad_sequences() 메서드의 padding 파라미터에서 'pre'을 주면 앞으로(좌측으로) 0을 채우는 패딩 작용함. "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(9) feature, target 데이터셋으로 분할하기. \n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "#(10) target 변수 원핫인코딩처리하기.  \n",
    "Y = to_categorical(y, voca_size)                              \n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((11, 5), (11, 12))"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "#(11) feature, target 변수의 차원 확인하기. \n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 5, 4)              48        \n_________________________________________________________________\nsimple_rnn (SimpleRNN)       (None, 32)                1184      \n_________________________________________________________________\ndense (Dense)                (None, 12)                396       \n=================================================================\nTotal params: 1,628\nTrainable params: 1,628\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#06. Simple RNN을 이용해 텍스트 (미리보기) 생성하기. \n",
    "#(1) 모델 정의하기. \n",
    "model = Sequential([\n",
    "    Embedding(voca_size, 4, input_length=(max_len-1)),\n",
    "    SimpleRNN(32),\n",
    "    Dense(voca_size, activation='softmax')\n",
    "])\n",
    "\n",
    "#(2) 모델의 요약 정보 확인하기. \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9090909361839294"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#(3) 모델의 compile 설정하기. \n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics='accuracy'\n",
    ")\n",
    "\n",
    "#(4) 모델 학습하기. \n",
    "model_fit = model.fit(X,Y, epochs=200, verbose=0)\n",
    "\n",
    "#(5) 훈련 최종 accuracy 확인하기. \n",
    "model_fit.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'경마장에 말이 말이 뛰고'"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "#07. 모델 검증하기. \n",
    "#(1) 검증용 함수 정의하기. (by github.com/ckiekim)\n",
    "def sentence_generation(model, t, max_len, current_word, n) :                   # 모델, 토크나이저, 최대글자수, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word                                                    # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
    "    sentence = ''\n",
    "    for _ in range(n) :                                                         # n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0]                       # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')     # 데이터에 대한 패딩\n",
    "        result = np.argmax(model.predict(encoded), axis=-1)                     # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.   \n",
    "        for word, index in t.word_index.items() : \n",
    "            if index == result:                                                 # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면, 예측단어이므로 break\n",
    "                break\n",
    "        current_word = current_word + ' '  + word                               # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        sentence = sentence + ' ' + word                                        # 예측 단어를 문장에 저장\n",
    "\n",
    "    sentence = init_word + sentence\n",
    "    return sentence\n",
    "\n",
    "#(2) 검증하기.\n",
    "sentence_generation(model, t, max_len, '경마장에', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'그의 말이 법이다'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "sentence_generation(model, t, max_len, '그의', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'가는 말이 고와야 오는 말이 곱다'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "sentence_generation(model, t, max_len, '가는', 5)"
   ]
  }
 ]
}