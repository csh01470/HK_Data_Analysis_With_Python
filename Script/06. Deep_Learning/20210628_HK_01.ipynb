{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5b56da8208ae380fa2c15171ec3bd1c59fd37e61d99a7ebd9f8c7e6e7af5d3db"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021.06.28. MON \n",
    "#Hankyeong\n",
    "\n",
    "##CH01. Tensorflow-Keras DNN 기본\n",
    "#00. 패키지 호출\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#00-1. #00-1. 씨드넘버 정의하기. \n",
    "np.random.seed(2021)\n",
    "tf.random.set_seed(2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      0   1     2     3   4   5   6   7   8   9   10  11  12  13  14  15  16  \\\n",
       "0    293   1  3.80  2.80   0   0   0   0   0   0  12   0   0   0   1   0  62   \n",
       "1      1   2  2.88  2.16   1   0   0   0   1   1  14   0   0   0   1   0  60   \n",
       "2      8   2  3.19  2.50   1   0   0   0   1   0  11   0   0   1   1   0  66   \n",
       "3     14   2  3.98  3.06   2   0   0   0   1   1  14   0   0   0   1   0  80   \n",
       "4     17   2  2.21  1.88   0   0   1   0   0   0  12   0   0   0   1   0  56   \n",
       "..   ...  ..   ...   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "465   98   6  3.04  2.40   2   0   0   0   1   0  11   0   0   0   1   0  76   \n",
       "466  369   6  3.88  2.72   1   0   0   0   1   0  12   0   0   0   1   0  77   \n",
       "467  406   6  5.36  3.96   1   0   0   0   1   0  12   0   0   0   0   0  62   \n",
       "468   25   8  4.32  3.20   0   0   0   0   0   0  11   0   0   0   0   0  58   \n",
       "469  447   8  5.20  4.10   0   0   0   0   0   0  12   0   0   0   0   0  49   \n",
       "\n",
       "     17  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  \n",
       "3     1  \n",
       "4     0  \n",
       "..   ..  \n",
       "465   0  \n",
       "466   0  \n",
       "467   0  \n",
       "468   1  \n",
       "469   0  \n",
       "\n",
       "[470 rows x 18 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>293</td>\n      <td>1</td>\n      <td>3.80</td>\n      <td>2.80</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2.88</td>\n      <td>2.16</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>60</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>2</td>\n      <td>3.19</td>\n      <td>2.50</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>66</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14</td>\n      <td>2</td>\n      <td>3.98</td>\n      <td>3.06</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>80</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>2</td>\n      <td>2.21</td>\n      <td>1.88</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>56</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>465</th>\n      <td>98</td>\n      <td>6</td>\n      <td>3.04</td>\n      <td>2.40</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>76</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>466</th>\n      <td>369</td>\n      <td>6</td>\n      <td>3.88</td>\n      <td>2.72</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>77</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>467</th>\n      <td>406</td>\n      <td>6</td>\n      <td>5.36</td>\n      <td>3.96</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>25</td>\n      <td>8</td>\n      <td>4.32</td>\n      <td>3.20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>58</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>469</th>\n      <td>447</td>\n      <td>8</td>\n      <td>5.20</td>\n      <td>4.10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>49</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>470 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#01. 폐암환자의 수술 전 데이터로 수술 후 생존 유무 분류하기. \n",
    "#(1) 폐암환자 데이터셋 불러오기. \n",
    "thoraric_surgery = pd.read_csv('../../data/thoraricsurgery.csv', header=None)\n",
    "thoraric_surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((352, 17), (118, 17), (352,), (118,))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#(2) train, test 데이터셋 분할하기. \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    thoraric_surgery.iloc[:,:-1].values, thoraric_surgery.iloc[:,-1].values, test_size=0.25, random_state=2021, stratify=thoraric_surgery.iloc[:,-1].values\n",
    ")\n",
    "\n",
    "#(3) train, test 데이터셋 차원 확인하기. \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 30)                540       \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 31        \n=================================================================\nTotal params: 571\nTrainable params: 571\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#(4) 모델 정의하기. \n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_shape=(17,), activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#(5) 모델 요약 정보 확인하기. \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 14.1449 - accuracy: 0.0667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 6.7747 - accuracy: 0.2847 - val_loss: 2.7294 - val_accuracy: 0.6338\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.2952 - accuracy: 0.6940 - val_loss: 2.9131 - val_accuracy: 0.6901\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.9590 - accuracy: 0.7865 - val_loss: 2.7423 - val_accuracy: 0.7042\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.7152 - accuracy: 0.8185 - val_loss: 2.1955 - val_accuracy: 0.7183\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.2688 - accuracy: 0.8185 - val_loss: 1.3525 - val_accuracy: 0.7183\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7266 - accuracy: 0.8114 - val_loss: 0.7041 - val_accuracy: 0.7183\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.8007 - val_loss: 0.6523 - val_accuracy: 0.7324\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8505 - val_loss: 0.6818 - val_accuracy: 0.7606\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8577 - val_loss: 0.6435 - val_accuracy: 0.7606\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.8577 - val_loss: 0.6561 - val_accuracy: 0.7606\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8577 - val_loss: 0.6352 - val_accuracy: 0.7606\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.8577 - val_loss: 0.6267 - val_accuracy: 0.7606\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4219 - accuracy: 0.8577 - val_loss: 0.6742 - val_accuracy: 0.7606\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8577 - val_loss: 0.6126 - val_accuracy: 0.7746\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.8577 - val_loss: 0.6148 - val_accuracy: 0.7746\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4085 - accuracy: 0.8577 - val_loss: 0.6109 - val_accuracy: 0.7746\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8577 - val_loss: 0.6540 - val_accuracy: 0.7746\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8577 - val_loss: 0.5950 - val_accuracy: 0.7606\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8577 - val_loss: 0.6534 - val_accuracy: 0.7746\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8577 - val_loss: 0.5927 - val_accuracy: 0.7746\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8541 - val_loss: 0.6230 - val_accuracy: 0.7887\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8612 - val_loss: 0.5920 - val_accuracy: 0.7746\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.8577 - val_loss: 0.6492 - val_accuracy: 0.7887\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8577 - val_loss: 0.6011 - val_accuracy: 0.7887\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8612 - val_loss: 0.5882 - val_accuracy: 0.7746\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8612 - val_loss: 0.5879 - val_accuracy: 0.7887\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8612 - val_loss: 0.5851 - val_accuracy: 0.7887\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3882 - accuracy: 0.8612 - val_loss: 0.6280 - val_accuracy: 0.7887\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8612 - val_loss: 0.5918 - val_accuracy: 0.7746\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8612 - val_loss: 0.6224 - val_accuracy: 0.7887\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e03555490>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#(6) 모델 실행환경(컴파일) 설정하기. \n",
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#(7) 모델 학습하기. \n",
    "model.fit(X_train, y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=30,\n",
    "          batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4/4 [==============================] - 0s 494us/step - loss: 0.4715 - accuracy: 0.8475\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.47146737575531006, 0.8474576473236084]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#(8) 모델 예측 및 평가하기. \n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((352, 17), (352,), (118, 17), (118,))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#02. 머신러닝 성능과 비교하기. \n",
    "#(1) 데이터셋 스케일링 처리하기. \n",
    "scaler = MinMaxScaler()\n",
    "X_scaling = scaler.fit_transform(thoraric_surgery.iloc[:,:-1])\n",
    "\n",
    "#(2) train, test 데이터셋으로 분리하기. \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaling, thoraric_surgery.iloc[:,-1].values, test_size=0.25, random_state=2021, stratify=thoraric_surgery.iloc[:,-1].values\n",
    ")\n",
    "\n",
    "#(3) train, test 데이터셋의 차원 확인하기. \n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8389830508474576"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#(4) LogisticRegression() 모델 할당하기. \n",
    "lr = LogisticRegression()\n",
    "\n",
    "#(5) 모델 훈련하기. \n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "#(6) 모델 예측 및 평가하기. \n",
    "accuracy_score(y_test, lr.predict(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEMO. 정형데이터분석은 머신러닝과 딥러닝의 성능 차이가 크지 않을 수 있음. 다만, 비정형데이터에서는 딥러닝의 성능이 월등함. "
   ]
  }
 ]
}