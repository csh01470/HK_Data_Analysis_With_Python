{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "389278cbb61c1c57cad107a3c1fdd79953aeebb4509d1d7f21aea6fe620a6af8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021.06.21. MON\n",
    "#Hankyeong\n",
    "\n",
    "##CH06. 앙상블(ensemble)\n",
    "#00. 패키지 호출\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#01. 데이터셋 전처리 및 분할하기. \n",
    "#(1) 데이터셋 불러오기\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2) 변수별로 Min-Max 스케일링하기. \n",
    "scaler = MinMaxScaler()\n",
    "cancer_mm = scaler.fit_transform(cancer.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3) train, test 데이터셋 분리하기. \n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    cancer_mm, cancer.target, stratify=cancer.target, test_size=0.2, random_state=2011\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#02. 로지스틱회귀, 서포트벡터머신, knn 모형으로 앙상블 모델(Hard Voting) 만들기. \n",
    "#(1) 모델 설정하기. \n",
    "lr = LogisticRegression()\n",
    "svc = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "vo_clf = VotingClassifier(\n",
    "    estimators=[('lr',lr),('svc',svc),('knn',knn)],\n",
    "    voting='hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()), ('svc', SVC()),\n",
       "                             ('knn', KNeighborsClassifier())])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#(2) 모델 학습하기. \n",
    "vo_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#(3) 모델 예측 및 평가하기. \n",
    "pred = vo_clf.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of LogisticRegression = 0.9386\nAccuracy of SVC = 0.9649\nAccuracy of KNeighborsClassifier = 0.9561\n"
     ]
    }
   ],
   "source": [
    "#PLUS. 개별 모델의 학습, 예측, 평가하기. \n",
    "for classifier in [lr, svc, knn] :\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    score = accuracy_score(y_test,pred)\n",
    "    classifier_name = classifier.__class__.__name__\n",
    "    print(f'Accuracy of {classifier_name} = {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('knn', KNeighborsClassifier())],\n",
       "                 voting='soft')"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "#03. 로지스틱회귀, 서포트벡터머신, knn 모형으로 앙상블 모델(Soft Voting) 만들기. \n",
    "#(1) 모델 설정하기. \n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "vo_clf = VotingClassifier(\n",
    "    estimators=[('lr',lr),('knn',knn)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "#(2) 모델 학습하기. \n",
    "vo_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEMO. SVM은 Soft Voting이 불가함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "#(3) 모델 예측 및 평가하기. \n",
    "pred = vo_clf.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  }
 ]
}