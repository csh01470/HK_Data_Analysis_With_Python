{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "389278cbb61c1c57cad107a3c1fdd79953aeebb4509d1d7f21aea6fe620a6af8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021.06.25. FRI. \n",
    "#Hankyeong\n",
    "\n",
    "#00. 패키지 호출\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#00-1. warning message ignore\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 145791 entries, 0 to 145790\nData columns (total 3 columns):\n #   Column    Non-Null Count   Dtype \n---  ------    --------------   ----- \n 0   id        145791 non-null  int64 \n 1   document  145791 non-null  object\n 2   label     145791 non-null  int64 \ndtypes: int64(2), object(1)\nmemory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#21. 네이버 영화 리뷰 데이터로 한글 감성 분석하기. & TF-IDF Vectorizer\n",
    "#(1) 데이터셋 불러오기. \n",
    "review_train = pd.read_csv('D://Python_Project/Hankyeong_DataAnalysis/Data/naver_movie_review_train.csv', sep='\\t')\n",
    "review_test = pd.read_csv('D://Python_Project/Hankyeong_DataAnalysis/Data/naver_movie_review_test.csv', sep='\\t')\n",
    "\n",
    "#(2) train 데이터셋 탐색하기. \n",
    "#①행, 열, 타입 확인하기. \n",
    "review_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#②결측치 확인하기. \n",
    "review_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 48995 entries, 0 to 48994\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   id        48995 non-null  int64 \n 1   document  48995 non-null  object\n 2   label     48995 non-null  int64 \ndtypes: int64(2), object(1)\nmemory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#(3) test 데이터셋 탐색하기. \n",
    "#①행, 열, 타입 확인하기. \n",
    "review_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#②결측치 확인하기. \n",
    "review_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 3min 52s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 2),\n",
       "                tokenizer=<function okt_tokenizer at 0x0000027AC6D73040>)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#22. tokenizer 함수 정의하기. \n",
    "#(1) 형태소 분리 객체 설정하기. \n",
    "okt = Okt()\n",
    "\n",
    "#(2) 불용어 설정하기. \n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을']\n",
    "\n",
    "#(3) 함수 정의하기. \n",
    "def okt_tokenizer(text) : \n",
    "    tokens = okt.morphs(text, stem=True)\n",
    "    tokens = [word for word in tokens if not word in stopwords ]\n",
    "    return tokens\n",
    "\n",
    "#(4) TF-IDF Vectorizer 객체 설정하기. \n",
    "tfid_vect = TfidfVectorizer(tokenizer=okt_tokenizer, \n",
    "                            ngram_range=(1,2))\n",
    "\n",
    "#(5) review_train 데이터셋을 넣어 벡터화하기. \n",
    "%time tfid_vect.fit(review_train['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(6) transform() 메서드를 이용해 벡터화하기. \n",
    "X_train_tv = tfid_vect.transform(review_train.document)\n",
    "X_test_tv = tfid_vect.transform(review_test.document)\n",
    "\n",
    "#(7) y_train, y_test 데이터셋 정의하기. \n",
    "y_train = review_train['label'].values\n",
    "y_test = review_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "#23. Naive Bayes 모델로 분류하기. \r\n",
    "#(1) 모델 정의하기. \r\n",
    "nb = MultinomialNB()\r\n",
    "\r\n",
    "#(2) 모델의 하이퍼파라미터 확인하기. \r\n",
    "nb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [0, 0.25, 0.5, 0.75, 1]})"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "#(3) GridSearch를 위한 하이퍼파라미터 값 지정하기. (recycle)\n",
    "params = {\n",
    "    'alpha'     : [0,0.25,0.5,0.75,1,]\n",
    "}\n",
    "\n",
    "#(4) GridsearchCV() 메서드를 이용해 훈련 모델 할당하기. \n",
    "gscv_nb = GridSearchCV(nb, param_grid=params)\n",
    "\n",
    "#(5) 모형 학습하기. \n",
    "gscv_nb.fit(X_train_tv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'alpha': 0.5}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#(6) 최적 하이퍼 파라미터 확인하기. \n",
    "gscv_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8576660877148417"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "#(7) 최적 파라미터에 대한 평가 점수 확인하기. \n",
    "gscv_nb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8615368915195428"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#(8) test 데이터셋으로 모형 예측 및 평가하기. \n",
    "accuracy_score(y_test,gscv_nb.predict(X_test_tv))"
   ]
  }
 ]
}